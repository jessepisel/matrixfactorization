{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.preprocessing import binarize\n",
    "from colorsys import hsv_to_rgb\n",
    "from random import randint, uniform\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Formation</th>\n",
       "      <th>SS</th>\n",
       "      <th>MD</th>\n",
       "      <th>Observation number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37168</td>\n",
       "      <td>CROMER KNOLL GP. Top</td>\n",
       "      <td>6063.10</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37168</td>\n",
       "      <td>Roedby Fm. Top</td>\n",
       "      <td>6063.10</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37168</td>\n",
       "      <td>Sola Fm. Top</td>\n",
       "      <td>6032.10</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37168</td>\n",
       "      <td>Aasgard Fm. Top</td>\n",
       "      <td>6016.10</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37168</td>\n",
       "      <td>VESTLAND GP. Top</td>\n",
       "      <td>5171.12</td>\n",
       "      <td>2274.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     API             Formation       SS      MD  Observation number\n",
       "0  37168  CROMER KNOLL GP. Top  6063.10  1382.0                   1\n",
       "1  37168        Roedby Fm. Top  6063.10  1382.0                   1\n",
       "2  37168          Sola Fm. Top  6032.10  1413.0                   1\n",
       "3  37168       Aasgard Fm. Top  6016.10  1429.0                   1\n",
       "4  37168      VESTLAND GP. Top  5171.12  2274.0                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops = pd.read_csv(r\"norway.csv\") #read in the top data\n",
    "tops.rename(columns={'TVDSS':'SS'}, inplace=True)\n",
    "\n",
    "ssmin = tops.SS.min()\n",
    "tops.SS = tops.SS - ssmin #standardize the subsea values\n",
    "\n",
    "tops.dropna(inplace=True)\n",
    "tops = tops[tops['Observation number'] == 1]\n",
    "tops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size is 16700 tops, and test size is 4175 tops\n",
      "Starting Iterations\n",
      "166.05727274749785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#tops.drop(['MD', 'GL', 'DELEV', 'DT'], axis=1, inplace=True)\n",
    "def sample_splitter(dataframe, fraction, randomseed):\n",
    "    test = dataframe.sample(frac=fraction, random_state=randomseed)\n",
    "    test_idx = test.index.values\n",
    "    train =  dataframe.drop(test_idx)\n",
    "    return train, test\n",
    "\n",
    "train, test = sample_splitter(tops, 0.2, 86)\n",
    "\n",
    "print(f'Training size is {len(train)} tops, and test size is {len(test)} tops')\n",
    "\n",
    "D_df = train.pivot_table(\"SS\", \"Formation\", \"API\").fillna(0)#pivot table to move into sparse matrix land\n",
    "R = D_df.values\n",
    "A = binarize(R) \n",
    "\n",
    "\n",
    "#ALS factorization from \n",
    "# https://github.com/mickeykedia/Matrix-Factorization-ALS/blob/master/ALS%20Python%20Implementation.py\n",
    "# here items are the formation and users are the well\n",
    "def runALS(A, R, n_factors, n_iterations, lambda_):\n",
    "    \"\"\"\n",
    "    Runs Alternating Least Squares algorithm in order to calculate matrix.\n",
    "    :param A: User-Item Matrix with ratings\n",
    "    :param R: User-Item Matrix with 1 if there is a rating or 0 if not\n",
    "    :param n_factors: How many factors each of user and item matrix will consider\n",
    "    :param n_iterations: How many times to run algorithm\n",
    "    :param lambda_: Regularization parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(\"Initiating \")\n",
    "    lambda_ = lambda_\n",
    "    n_factors = n_factors\n",
    "    n, m = A.shape\n",
    "    n_iterations = n_iterations\n",
    "    np.random.seed(86)\n",
    "    Users = 5 * np.random.rand(n, n_factors, )\n",
    "    Items = 5 * np.random.rand(n_factors, m)\n",
    "\n",
    "    def get_error(A, Users, Items, R):\n",
    "        # This calculates the MSE of nonzero elements\n",
    "        return np.sum((R * (A - np.dot(Users, Items))) ** 2) / np.sum(R)\n",
    "\n",
    "    MAE_List = []\n",
    "\n",
    "    print(\"Starting Iterations\")\n",
    "    for iter in range(n_iterations):\n",
    "        for i, Ri in enumerate(R):\n",
    "            Users[i] = np.linalg.solve(\n",
    "                np.dot(Items, np.dot(np.diag(Ri), Items.T))\n",
    "                + lambda_ * np.eye(n_factors),\n",
    "                np.dot(Items, np.dot(np.diag(Ri), A[i].T)),\n",
    "            ).T\n",
    "     #   print(\n",
    "     #       \"Error after solving for User Matrix:\",\n",
    "     #       get_error(A, Users, Items, R),\n",
    "     #   )\n",
    "\n",
    "        for j, Rj in enumerate(R.T):\n",
    "            Items[:, j] = np.linalg.solve(\n",
    "                np.dot(Users.T, np.dot(np.diag(Rj), Users))\n",
    "                + lambda_ * np.eye(n_factors),\n",
    "                np.dot(Users.T, np.dot(np.diag(Rj), A[:, j])),\n",
    "            )\n",
    "     #   print(\n",
    "     #       \"Error after solving for Item Matrix:\",\n",
    "     #       get_error(A, Users, Items, R),\n",
    "     #   )\n",
    "\n",
    "        MAE_List.append(get_error(A, Users, Items, R))\n",
    "     #   print(\"%sth iteration is complete...\" % iter)\n",
    "    \n",
    "   # print(MSE_List)\n",
    "   # fig = plt.figure()\n",
    "   # ax = fig.add_subplot(111)\n",
    "   # plt.plot(range(1, len(MSE_List) + 1), MSE_List); plt.ylabel('Error'); plt.xlabel('Iteration')\n",
    "   # plt.title('Python Implementation MSE by Iteration \\n with %d formations and %d wells' % A.shape);\n",
    "    # plt.savefig('Python MSE Graph.pdf', format='pdf')\n",
    "    return Users, Items\n",
    "\n",
    "U, Vt = runALS(R, A, 3, 100, 0.1)\n",
    "\n",
    "recommendations = np.dot(U, Vt) #get the recommendations\n",
    "\n",
    "recsys = pd.DataFrame(\n",
    "    data=recommendations[0:, 0:], index=D_df.index, columns=D_df.columns\n",
    ") #results\n",
    "\n",
    "newDF = recsys.T\n",
    "newDF.reset_index(inplace=True)\n",
    "\n",
    "flat_preds = pd.DataFrame(recsys.unstack()).reset_index()\n",
    "\n",
    "new_df = pd.merge(test, flat_preds,  how='left', left_on=['API','Formation'], right_on = ['API','Formation'])\n",
    "\n",
    "new_df.rename(columns={0:'SS_pred'}, inplace=True)\n",
    "\n",
    "cleanDF = new_df.dropna()\n",
    "\n",
    "cleanDF['signed_error'] = (cleanDF['SS'] - cleanDF['SS_pred'])\n",
    "\n",
    "print(MAE(cleanDF.SS.values-ssmin, cleanDF.SS_pred.values-ssmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataframe, random_seed, latent_vectors, n_iters):\n",
    "    np.random.seed(random_seed)\n",
    "    block_1  = np.random.choice(dataframe.index, size=dataframe.shape[0]//4)\n",
    "    tops2 = dataframe.drop(block_1)\n",
    "    block_2 = np.random.choice(tops2.index, size=tops.shape[0]//4)\n",
    "    tops3 = tops2.drop(block_2)\n",
    "    block_3 = np.random.choice(tops3.index, size=tops.shape[0]//4)\n",
    "    tops4 = tops3.drop(block_3)\n",
    "    block_4 = np.random.choice(tops4.index, size=tops.shape[0]//4)\n",
    "    blocks = [block_1, block_2, block_3, block_4]\n",
    "    CV_MAE = []\n",
    "    for block in blocks:\n",
    "        validate = dataframe.loc[block]\n",
    "        main_group = dataframe.drop(block)\n",
    "        print(f'Validating on {block.shape[0]} tops')\n",
    "        D_df = main_group.pivot_table(\"SS\", \"Formation\", \"API\").fillna(0)#pivot table to move into sparse matrix land\n",
    "        R = D_df.values\n",
    "        A = binarize(R) \n",
    "\n",
    "        \n",
    "        U, Vt = runALS(R, A, latent_vectors, n_iters, 0.1)\n",
    "\n",
    "        recommendations = np.dot(U, Vt) #get the recommendations\n",
    "\n",
    "        recsys = pd.DataFrame(\n",
    "            data=recommendations[0:, 0:], index=D_df.index, columns=D_df.columns\n",
    "        ) #results\n",
    "\n",
    "        newDF = recsys.T\n",
    "        newDF.reset_index(inplace=True)\n",
    "\n",
    "        flat_preds = pd.DataFrame(recsys.unstack()).reset_index()\n",
    "\n",
    "        new_df = pd.merge(validate, flat_preds,  how='left', left_on=['API','Formation'], right_on = ['API','Formation'])\n",
    "\n",
    "        new_df.rename(columns={0:'SS_pred'}, inplace=True)\n",
    "\n",
    "        cleanDF = new_df.dropna()\n",
    "\n",
    "        cleanDF['signed_error'] = (cleanDF['SS'] - cleanDF['SS_pred'])\n",
    "\n",
    "        CV_MAE.append(MAE(cleanDF.SS.values-ssmin, cleanDF.SS_pred.values-ssmin))\n",
    "\n",
    "    return CV_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating on 5218 tops\n",
      "Starting Iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrp4932\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating on 5218 tops\n",
      "Starting Iterations\n"
     ]
    }
   ],
   "source": [
    "cross_validation(tops, 86, 4, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
